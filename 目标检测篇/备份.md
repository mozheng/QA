


1. 在你的项目中为什么选用YOLOv5模型而不用v4？
   YOLOv4和v5都是YOLO系列性能非常优秀的算法，性能上不分伯仲，而且最近出来的scale YOLOv4更是达到了55的map。在项目中选择v5的原因是因为在v4、v5出来之前，就一直在用U版的YOLOv3，相对于原版的v3，做了很多改进，而V5是在这个hub的基础上改进的，用起来上手比较快，而且代码和之前的v3相似度很高，可以无缝对接以前的项目。另一方面，v5可选的模型比较多，在速度和精度上对比v4有一定的优势，而且模型采用半精度存储，模型很小，训练和推理上都很友好。通常用s或者m版本的基本上都可以满足项目需求。

比较官方一点的回答：
使用Pytorch框架，对用户非常友好，能够方便地训练自己的数据集，相对于YOLOV4采用的Darknet框架，Pytorch框架更容易投入生产。
代码易读，整合了大量的计算机视觉技术，非常有利于学习和借鉴。
不仅易于配置环境，模型训练也非常快速，并且批处理推理产生实时结果。
能够直接对单个图像，批处理图像，视频甚至网络摄像头端口输入进行有效推理。
能够轻松的将Pytorch权重文件转化为安卓使用的ONXX格式，然后可以转换为OPENCV的使用格式，或者通过CoreML转化为IOS格式，直接部署到手机应用端。
最后YOLO V5s高达140FPS的对象识别速度令人印象非常深刻，使用体验非常棒。

10. 介绍YOLOv5中Focus模块的原理和作用
    Focus模块，将W、H信息集中到通道空间，输入通道扩充了4倍，作用是可以使信息不丢失的情况下提高计算力。具体操作为把一张图片每隔一个像素拿到一个值，类似于邻近下采样，这样我们就拿到了4张图，4张图片互补，长的差不多，但信息没有丢失，拼接起来相当于RGB模式下变为12个通道，通道多少对计算量影响不大，但图像缩小，大大减少了计算量。

以YOLOv5s的结构为例，原始640×640×3的图像输入Focus结构，采用切片操作，先变成320×320×12的特征图，再经过一次32个卷积核的卷积操作，最终变成320×320×32的特征图。

11.YOLOv4和v5均引入了CSP结构，介绍一下它的原理和作用；

CSP结构是一种思想，它和ResNet、DenseNet类似，可以看作是DenseNet的升级版，它将feature map拆成两个部分，一部分进行卷积操作，另一部分和上一部分卷积操作的结果进行concate。主要解决了三个问题：1. 增强CNN的学习能力，能够在轻量化的同时保持着准确性；2. 降低计算成本；3. 降低内存开销。CSPNet改进了密集块和过渡层的信息流，优化了梯度反向传播的路径，提升了网络的学习能力，同时在处理速度和内存方面提升了不少。










YOLO、SSD和Faster-RCNN的区别，他们各自的优势和不足分别是什么？
YOLO、SSD和Faster-RCNN都是目标检测领域里面非常经典的算法，无论是在工业界还是学术界，都有着深远的影响；Faster-RCNN是基于候选区域的双阶段检测器代表作，而YOLO和SSD则是单阶段检测器的代表；在速度上，单阶段的YOLO和SSD要比双阶段的Faster-RCNN的快很多，而YOLO又比SSD要快，在精度上，Faster-RCNN精度要优于单阶段的YOLO和SSD；不过这也是在前几年的情况下，目标检测发展到现在，单阶段检测器精度已经不虚双阶段，并且保持着非常快的速度，现阶段SSD和Faster-RCNN已经不更了，但是YOLO仍在飞快的发展，目前已经迭代到V4、V5，速度更快，精度更高，在COCO精度上双双破了50map，这是很多双阶段检测器都达不到的精度，而最近的Scale YOLOv4更是取得了55map，成功登顶榜首。当然虽然SSD和Faster-RCNN已经不更了，但是有很多他们相关的变体，同样有着不错的精度和性能，例如Cascade R-CNN、RefineDet等等。

1. 介绍一下CenterNet的原理，它与传统的目标检测有什么不同点？

CenterNet是属于anchor-free系列的目标检测算法的代表作之一，与它之前的目标算法相比，速度和精度都有不小的提高，尤其是和YOLOv3相比，在速度相同的情况下，CenterNet精度要比YOLOv3高好几个点。它的结构非常的简单，而且不需要太多了后处理，连NMS都省了，直接检测目标的中心点和大小，实现了真正的anchor-free。CenterNet论文中用到了三个主干网络：ResNet-18、DLA-34和Hourglass-104，实际应用中，也可以使用resnet-50等网络作为backbone；CenterNet的算法流程是：一张512512（1x3x512x512）的图片输入到网络中，经过backbone特征提取后得到下采样32倍后的特征图（1x2048x16x16），然后再经过三层反卷积模块上采样到128128的尺寸，最后分别送入三个head分支进行预测：分别预测物体的类别、长宽尺寸和中心点偏置。其中推理的核心是从headmap中提取需要的bounding box，通过使用3*3的最大池化，检查当前热点的值是否比周围的8个临近点值都大，每个类别取100个这样的点，经过box后处理后再进行阈值筛选，得到最终的预测框。
目标检测网络CenterNet详解
扔掉anchor！真正的CenterNet
CenterNet推理过程理解

5. CenterNet中heatmap（热力图）如何生成？

heatmap的生成可以通过高斯核公式来理解，其中(x，y)为待检测图像中枚举的步长块位置，(px，py)为低分辨率图像中对应于GT关键点的坐标。可以看出，当枚举块的位置和GT关键点坐标接近重合的时候，高斯核输出值接近为1；当枚举块位置和GT关键点相差很大时，高斯核输出值接近为0.这样一来经过高斯核映射后的每个关键点（块）高斯热图为：

每个点的范围是0-1，而1则代表 这个目标的中心点，也就是要预测学习的点，该点处为最大值，沿着半径向外按高斯函数递减 。一个类别对应一张heatmap，80个类别则有80张heatmap，若还有一只狗，则狗的keypoint再另一张heatmap上。

6. 你知道哪些边缘端部署的方案？
   目前大多数深度学习算法模型要落地对算力要求还是比较高的，如果在服务器上，可以使用GPU进行加速，但是在边缘端或者算力匮乏的开发板子上，不得不对模型进一步的压缩或者改进，也可以针对特定的场景使用市面上现有的推理优化加速框架进行推理。目前来说比较常见的几种部署方案为：
   nvidia GPU：pytorch->onnx->TensorRT
   intel CPU： pytorch->onnx->openvino
   移动端（手机、开发板等）：pytorch->onnx->MNN、NCNN、TNN、TF-lite、Paddle-lite、RKNN等
7. 你最常用的几种目标检测算法是什么？为什么选择这些算法，你选择它们的场景分别是什么？
   在工作中，我通常会根据不同的任务选取不同的算法模型：
   目标检测：YOLOv5、YOLOv3、CenterNet、SSD、Faster RCNN、EfficientDet；
   图像分类：mobileNetv2、mobileNetv3、ghostNet、ResNet系列、ShuffleNetV2、EfficientNet；
   实例分割：mask-rcnn、yolact、solo；
   语义分割：deeplabv3、deeplabv3+、UNet；
   文本检测：CTPN、PSENet、DBNet、YOLOV5；
   文本识别：CRNN+CTC、CRNN+Attention；
   通常，我比较喜欢性能好的模型，性能的指标由两部分，一个是精度，一个是速度。比如在目标检测中，用的比较多的是YOLO系列，特别是v4、v5出来后。通常在图像分类的任务上，分类并不困难的情况下会选择一些轻量型的网络，能够一定程度上节省算力资源。其他领域的任务算法抉择也大同小异。



12. 你还了解当下哪些比较流行的目标检测算法？
    目前比较流行的目标检测算法有以下几种类型，不局限于这几种：
    anchor-based：YOLOv3、YOLOv4、YOLOv5、pp-YOLO、SSD、Faster-R-CNN、Cascade R-CNN、EfficientDet，RetinaNet、MTCNN；
    anchor-free：CornerNet、CenterNet、CornerNet-lite、FCOS；
    transform：DETR；
    mobile-detector：mobileNet-YOLO、mobileNet-SSD、tiny-YOLO、nanodet、YOLO-fastest、YOLObile、mobilenet-retinaNet、MTCNN；
    还有很多很多。。。mmdetection里面就实现了几十种，可以去看一看，这里面最想总结的是移动端的det，很多都是一些大佬在原生算法基础上的改进，有时间出一篇文章专门记录这个类型的检测器。
13. EfficentDet为什么可以做到速度兼精度并存 ？
14. 介绍Faster R-CNN和Cascade R-CNN

Faster-RCNN是基于候选区域的双阶段检测器代表作，总的来说可以分为四部分：首先是主干卷积网络的特征提取，然后是RPN层，RPN层通过softmax判断anchors属于positive或者negative，再利用边框回归修正anchors获得精确的候选区域，RPN生成了大量的候选区域，这些候选区域和feature maps一起送入ROI pooling中，得到了候选特征区域，最后送入分类层中进行类别判断和边框回归，得到最终的预测结果。

Cascade R-CNN算法是在Faster R-CNN上的改进，通过级联几个检测网络达到不断优化预测结果的目的，预普通的级联不同，Cascade R-CNN的几个检测网络是基于不同的IoU阈值确定的正负样本上训练得到的。简单来说cascade R-CNN是由一系列的检测模型组成，每个检测模型都基于不同IoU阈值的正负样本训练得到，前一个检测模型的输出作为后一个检测模型的输入，因此是stage by stage的训练方式，而且越往后的检测模型，其界定正负样本的IoU阈值是不断上升的。

15. SSD相比于YOLO做了哪些改进？

这里说的是SSD相对于YOLOv1的改进，因为现在SSD已经不更了，但是YOLO还如日中天，已经发展到v5，性能在目标检测算法里一骑绝尘。那么最原始的SSD相对于YOLOv1做了哪些改进呢？

SSD提取了不同尺度的特征图来做检测，而YOLO在检测是只用了最高层的Feature maps；
SSD引入了Faster-RCNN的anchor机制，采用了不同尺度和长宽比的先验框；
SSD网络结构是全卷积，采用卷积做检测，YOLO用到了FC（全连接）层；
16. 介绍SSD原理

SSD算法流程：
输入一幅图，让图片经过卷积神经网络（VGG）提取特征，生成feature map
抽取其中六层的feature map，然后分别在这些feature map层上面的每一个点构造4、个不同尺度大小的default box，然后分别进行检测和分类（各层的个数不同，但每个点都有）
将生成的所有default box都集合起来，全部丢到NMS中，输出筛选后的default box。

17. 了解哪些开源的移动端轻量型目标检测？

轻量型的目标检测其实有很多，大多数都是基于YOLO、SSD的改进，当然也有基于其他算法改的；比较常用的改进方法是使用轻量型的backbone替换原始的主干网络，例如mobilenet-ssd、mobilenet-YOLOv3、YOLO-fastest、YOLObile、YOLO-nano、nanodet、tiny-YOLO等等，在减少了计算量的同时保持着不错的精度，经过移动部署框架推理后，无论是在服务器还是移动端都有着不错的精度和速度。

18. 对于小目标检测，你有什么好的方案或者技巧？

图像金字塔和多尺度滑动窗口检测（MTCNN）
多尺度特征融合检测（FPN、PAN、ASFF等）
增大训练、检测图像分辨率；
超分策略放大后检测；
19. 介绍一下NMS和IoU的原理；

NMS全称是非极大值抑制，顾名思义就是抑制不是极大值的元素。在目标检测任务中，通常在解析模型输出的预测框时，预测目标框会非常的多，其中有很多重复的框定位到了同一个目标，NMS的作用就是用来除去这些重复框，从而获得真正的目标框。而NMS的过程则用到了IoU，IoU是一种用于衡量真实和预测之间相关度的标准，相关度越高，该值就越高。IoU的计算是两个区域重叠的部分除以两个区域的集合部分，简单的来说就是交集除以并集。

在NMS中，首先对预测框的置信度进行排序，依次取置信度最大的预测框与后面的框进行IoU比较，当IoU大于某个阈值时，可以认为两个预测框框到了同一个目标，而置信度较低的那个将会被剔除，依次进行比较，最终得到所有的预测框。

20. 目标检测单阶段和双阶段优缺点，双阶段的为什么比单阶段的效果要好？
21. 目标检测中如何处理正负样本不平衡的问题？
22. YOLOv3为什么这么快？

YOLOv3和SSD比网络更加深了，虽然anchors比SSD少了许多，但是加深的网络深度明显会增加更多的计算量，那么为什么YOLOv3会比SSD快3倍？
SSD用的很老的VGG16，V3用的其最新原创的Darknet，darknet-53与resnet的网络结构，darknet-53会先用1x1的卷积核对feature降维，随后再利用3x3的卷积核升维，这个过程中，就会大大降低参数的计算量以及模型的大小，有点类似于低秩分解。究其原因是做了很多优化，比如用卷积替代替代全连接，1X1卷积减小计算量等。

23. 你认为当前目标检测算法发展的趋势是什么？现阶段存在什么难点？
24. 你知道哪些模型压缩和推理优化的方案？
25. 模型部署
26. 介绍一下YOLOx，它相对于YOLOv3、YOLOv5做了哪些改进？这样改进取得了什么样的效果和好处？你怎么评价这篇论文？
27. 为了适配边缘部署要求，AI算法怎么做适配？
28. 在模型效果和效率之间怎么做平衡和取舍？怎么在不牺牲效果的前提下提高效率？
29. 算法上线后怎么持续做迭代？
30. 基于Anchor-base的目标检测算法相对于基于Anchor-free的目标检测算法有什么缺陷？

基于Anchor-base的目标检测算法需要在训练前通过聚类决定一系列的anchor，这些anchor具有很强的领域性，泛化差；
anchor机制增加了detection heads的复杂性，增加了预测数量，这在边缘AI系统中，是一个瓶颈。
anchor-free在YOLOx中的做法是：

在每个位置只预测一次，预测四个值：左上角xy坐标的偏移、宽、高。

将中心3X3=9的区域设置为正样本，称作：center sampling。

31. 解释一下YOLOx解藕头的设计思想

classification和 regression 是有冲突的，但是YOLO系列工作还是将两者放在一个head里面。

32. 解释YOLOx中SimOTA标签自动分配策略的思想
33. Transformer落地难点有哪些？
34. TensorRT的优化原理

算子融合（网络层合并）：简单来说就是通过融合一些计算op或者去掉一些多余op来减少数据流通次数以及显存的频繁使用来提速，融合之后的计算图的层次更少了，占用的CUDA核心数也少了，因此整个模型结构会更小，更快，更高效
低精度量化：量化即IN8量化或者FP16以及TF32等不同于常规FP32精度的使用，这些精度可以显著提升模型执行速度并且不会保持原先模型的精度，更低的数据精度将会使得内存占用和延迟更低，模型体积更小
cuda核自动调整：根据不同的显卡构架、SM数量、内核频率等，选择不同的优化策略以及计算方式，寻找最合适当前构架的计算方式，不同的硬件TensorRT 都会做对应的优化，得到优化后的engine
动态张量显存：在每个tensor的使用期间，TensorRT会为其指定显存，避免显存重复申请，减少内存占用和提高重复使用效率
多流执行：使用CUDA中的stream技术，最大化实现并行操作

$$


$$
