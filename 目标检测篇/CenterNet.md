# 介绍一下CenterNet的原理，它与传统的目标检测有什么不同点？

CenterNet是属于anchor-free系列的目标检测算法的代表作之一，与它之前的目标算法相比，速度和精度都有不小的提高，尤其是和YOLOv3相比，在速度相同的情况下，CenterNet精度要比YOLOv3高好几个点。它的结构非常的简单，而且不需要太多了后处理，连NMS都省了，直接检测目标的中心点和大小，实现了真正的anchor-free。CenterNet论文中用到了三个主干网络：ResNet-18、DLA-34和Hourglass-104，实际应用中，也可以使用resnet-50等网络作为backbone；CenterNet的算法流程是：一张 1x3x512x512 的图片输入到网络中，经过backbone特征提取后得到下采样32倍后的特征图（1x2048x16x16），然后再经过三层反卷积模块上采样到128128的尺寸，最后分别送入三个head分支进行预测：分别预测物体的类别、长宽尺寸和中心点偏置。其中推理的核心是从headmap中提取需要的bounding box，通过使用3*3的最大池化，检查当前热点的值是否比周围的8个临近点值都大，每个类别取100个这样的点，经过box后处理后再进行阈值筛选，得到最终的预测框。


## CenterNet中heatmap（热力图）如何生成？

heatmap的生成可以通过高斯核公式来理解，其中(x，y)为待检测图像中枚举的步长块位置，(px，py)为低分辨率图像中对应于GT关键点的坐标。可以看出，当枚举块的位置和GT关键点坐标接近重合的时候，高斯核输出值接近为1；当枚举块位置和GT关键点相差很大时，高斯核输出值接近为0.这样一来经过高斯核映射后的每个关键点（块）高斯热图为：

每个点的范围是0-1，而1则代表 这个目标的中心点，也就是要预测学习的点，该点处为最大值，沿着半径向外按高斯函数递减 。一个类别对应一张heatmap，80个类别则有80张heatmap，若还有一只狗，则狗的keypoint再另一张heatmap上。